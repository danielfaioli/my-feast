# My-Feast - Implementando uma Feature Store em um ecossistema de dados h√≠brido (On-Prem & Cloud)

## Overview

Este projeto √© uma demostra√ß√£o de uso de uma feature store em uma arquitetura de dados h√≠brida, composta por um data lake on-premises (Hadoop/HDFS) e um data lake na cloud (Azure Data Lake Gen2).

## Conceitos e Objetivos

    'Deploying ML is hard.'

A m√°xima acima, talvez exagerada (ou nem tanto), √© o principal motivo da exis√™ncia das Feature Stores. Em resumo, uma `feature store` √© um sistema respons√°vel por gerir, "armazenar" e servir dados, preprocessados, para modelos de ML. 

Em um pipeline, ou ciclo de vida, de um modelo, os processos de Feature Engineering e produtiza√ß√£o das features criadas demandam tempo e possuem grande complexidade; um cientista de dados atuando na cria√ß√£o de um conjunto de entidades e suas vari√°veis, n√£o √© capaz de, rapidamente e com autonomia, publicar suas features para treino e serving destes dados aos modelos de ML.

Uma feature store soluciona este problema, ao atuar como uma camada √∫nica de acesso aos dados, desacoplando o storage das features da recupera√ß√£o destas. Em ess√™ncia, uma feature store complementa o ecossistema de dados existente, ao fornecer uma camada de `gest√£o de metadados` das features que permite a `Descoberta`, `Compartilhamento` e `Reuso` de fetures em uma organiza√ß√£o, al√©m de servir dados de maneira `Consistente no tempo (point in time correctness data)`, evitando a ocorr√™ncia de desvios entre os dados de treino e serving do modelo (`Training-Serving skew`) e facilitando o processo de `Deploy de novas features.`

![Feature Store overall architecture](docs/img/feature-store-basic.png)

Neste projeto foi criada uma arquitetura h√≠brida, contando com um cluster [Spark Standalone](https://spark.apache.org/docs/latest/spark-standalone.html) e um [HDFS](https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html), ambos dockerizados e um lake na cloud, utilizando como Storage o [Azure Data Lake Gen2](https://docs.microsoft.com/en-us/azure/storage/blobs/data-lake-storage-introduction) e como engine de processamento e consumo anal√≠tico, a plataforma [Azure Databricks](https://docs.microsoft.com/en-us/azure/databricks/scenarios/what-is-azure-databricks). A feature store utilizada neste projeto √© o [Feast](https://docs.feast.dev/v/v0.20-branch/), um projeto Open Source, agn√≥stico em rela√ß√£o √† infraestrutura.

### Disclaimer - O que n√£o √© uma Feature Store

Sim, eu sei, aqui vai mais um disclaimer üòê. Apesar do clich√©, √© importante delimitar o que uma feature store `n√£o √©`:

* `Feature Store n√£o √© um Sistema de ETL/ELT`. A Feature Store n√£o √© (e n√£o pretende ser) um sistema *all purpose* para transforma√ß√£o ou de pipeline de dados. A Feature Store deve ser integrada aos pipelines de transforma√ß√£o de dados *upstream* . 
* `Feature Store n√£o √© um cat√°logo de dados`. A feature store n√£o √© um sistema especializado na cataloga√ß√£o e descoberta *all purpose* para os dados de uma organiza√ß√£o. A feature store busca catalogar features utilizadas em modelos de ML, dentro do escopo de facilitar o reuse destas features.
* `Feature Store n√£o √© um Data Warehouse`. De fato, a feature store √© uma camada *light-weight* capaz de gerenciar metadados e servir features, inclusive utilizando como fonte DWs existentes.

### Conceitos de Feature Store 
* Project: Top Level Namespace em uma Feature Store. Cada projeto, prov√™ um isolamento completo das features √† n√≠vel de infraestrutura; cada projeto deve ser entendido como um contexto inteiramente isolado de features, exemplos, `dev`, `staging`, `production`.
* Feature View: Usu√°rios definem features views; Uma feature view consiste de um Data Source e de uma rela√ß√£o entre Entidades -> Features. 
  * Data Source: Fonte dos dados "brutos", subjacente.
  * Entidades: Cole√ß√µes de features que s√£o semanticamente relacionadas. 
    * Name: Nome da Entidade
    * Join Keys: Identifica√ß√£o das chaves prim√°rias f√≠sicas
  * Feature Views: O Modelo de dados de uma feature store √© baseado em s√©ries temporais. Uma feature view √© um agrupamento de features, que podem ser encontrados em um mesmo data source e relacionadas √†(s) mesma(s) entidade(s).

![Feature Store Data Model](docs/img/feast-data-model.png)
  
* Offline Store: Armazenam dados hist√≥ricos das s√©ries temporais utilizados pelas features; podem ser Data Lakes, Data Warehouses etc (ex: HDFS, ADLS, Snowflake, Synapse, Redshift, etc).
* Online Store: Armazenam vetores para *serving* das features em baixa lat√™ncia. S√£o utilizados para realizar *feature lookups* online.
* Registry: Reposit√≥rio central de metadados; armazena a defini√ß√£o das features e todos os metadados relacionados. O feature registry √© utilizado na descoberta e recupera√ß√£o das features.     

O diagrama a seguir apresenta a arquitetura gen√©rica de uma feature store.

![A feature store overall architecture](docs/img/overall-architecture.png)

# Arquitetura e Funciamento do Projeto

O uso feature store √© escal√°vel quando este componente integra a arquitetura / infraestrutura do ecossistema de dados preexistente. Por este motivo, o uso de um sistema *light-weight*, que √© capaz de utilizar o *compute* e o *storage* existentes, sem modifica√ß√µes no ambiente, √© vantajoso. O Feast √© um SDK que conta com poucas (em alguns casos, possivelmente nenhuma) modifica√ß√£o na infraestrutura existente. O √∫nico novo componente adicionado na feature store √© o Feature Registry; atualmente s√£o utilizados *buckets* ou *object stores* para armazenamento dos metadados das features. A arquitetura deste case, demonstra a adi√ß√£o de uma feature store √† arquitetura de dados existente de uma grande organiza√ß√£o. 

O ecossistema de dados apresentado nesta demo, conta, previamente (simulado, a infra on-prem e na cloud foi profisionada para execu√ß√£o do case), com um cluster de Big Data on-prem com os seguintes componentes: Um Cluster Hadoop com um HDFS (1 Namenode e 1 Datanode - **n√£o foi provisionado um secondary namenode, por simplicidade**) e um cluster Spark Standalone (1 master e 2 worker nodes); na cloud, este ambiente √© composto de uma Storage Account com Hierarchical Namespace habilitado (Azure Data Lake Store Gen2), Workspace Databricks e um Azure Event Hub workspace. Os componentes de infraestrutura adicionados nesta infra (considera-se que s√£o componentes n√£o existentes na infra anterior) foram, uma Storage Account (Blob Storage), utlizada como camada de armazenamento dos arquivos do Feature Registry, e um Azure Cache for Redis, utilizado como Online Store para serving de feature vectors.

O diagrama abaixo apresenta a arquitetura descrita acima, bem como o fluxo de dados e metadados neste projeto.

![Feature Store in a Hybrid Data Lake Architecture](docs/img/case-architecture.jpg)