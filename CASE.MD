# My-Feast - Implementando uma Feature Store em um ecossistema de dados h√≠brido (On-Prem & Cloud)

## Overview

Este projeto √© uma demostra√ß√£o de uso de uma feature store em uma arquitetura de dados h√≠brida, composta por um data lake on-premises (Hadoop/HDFS) e um data lake na cloud (Azure Data Lake Gen2).

## Conceitos e Objetivos

    'Deploying ML is hard.'

A m√°xima acima, talvez exagerada (ou nem tanto), √© o principal motivo da exis√™ncia das Feature Stores. Em resumo, uma `feature store` √© um sistema respons√°vel por gerir, "armazenar" e servir dados, preprocessados, para modelos de ML. 

Em um pipeline, ou ciclo de vida, de um modelo, os processos de Feature Engineering e produtiza√ß√£o das features criadas demandam tempo e possuem grande complexidade; um cientista de dados atuando na cria√ß√£o de um conjunto de entidades e suas vari√°veis, n√£o √© capaz de, rapidamente e com autonomia, publicar suas features para treino e serving destes dados aos modelos de ML.

Uma feature store soluciona este problema, ao atuar como uma camada √∫nica de acesso aos dados, desacoplando o storage das features da recupera√ß√£o destas. Em ess√™ncia, uma feature store complementa o ecossistema de dados existente, ao fornecer uma camada de `gest√£o de metadados` das features que permite a `Descoberta`, `Compartilhamento` e `Reuso` de fetures em uma organiza√ß√£o, al√©m de servir dados de maneira `Consistente no tempo (point in time correctness data)`, evitando a ocorr√™ncia de desvios entre os dados de treino e serving do modelo (`Training-Serving skew`) e facilitando o processo de `Deploy de novas features.`

![Feature Store overall architecture](docs/img/feature-store-basic.png)

Neste projeto foi criada uma arquitetura h√≠brida, contando com um cluster [Spark Standalone](https://spark.apache.org/docs/latest/spark-standalone.html) e um [HDFS](https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html), ambos dockerizados e um lake na cloud, utilizando como Storage o [Azure Data Lake Gen2](https://docs.microsoft.com/en-us/azure/storage/blobs/data-lake-storage-introduction) e como engine de processamento e consumo anal√≠tico, a plataforma [Azure Databricks](https://docs.microsoft.com/en-us/azure/databricks/scenarios/what-is-azure-databricks). A feature store utilizada neste projeto √© o [Feast](https://docs.feast.dev/v/v0.20-branch/), um projeto Open Source, agn√≥stico em rela√ß√£o √† infraestrutura.

### Disclaimer - O que n√£o √© uma Feature Store

Sim, eu sei, aqui vai mais um disclaimer üòê. Apesar do clich√©, √© importante delimitar o que uma feature store `n√£o √©`:

* `Feature Store n√£o √© um Sistema de ETL/ELT`. A Feature Store n√£o √© (e n√£o pretende ser) um sistema *all purpose* para transforma√ß√£o ou de pipeline de dados. A Feature Store deve ser integrada aos pipelines de transforma√ß√£o de dados *upstream* . 
* `Feature Store n√£o √© um cat√°logo de dados`. A feature store n√£o √© um sistema especializado na cataloga√ß√£o e descoberta *all purpose* para os dados de uma organiza√ß√£o. A feature store busca catalogar features utilizadas em modelos de ML, dentro do escopo de facilitar o reuse destas features.
* `Feature Store n√£o √© um Data Warehouse`. De fato, a feature store √© uma camada *light-weight* capaz de gerenciar metadados e servir features, inclusive utilizando como fonte DWs existentes.

### Conceitos de Feature Store 
* Project: Top Level Namespace em uma Feature Store. Cada projeto, prov√™ um isolamento completo das features √† n√≠vel de infraestrutura; cada projeto deve ser entendido como um contexto inteiramente isolado de features, exemplos, `dev`, `staging`, `production`.
* Feature View: Usu√°rios definem features views; Uma feature view consiste de um Data Source e de uma rela√ß√£o entre Entidades -> Features. 
  * Data Source: Fonte dos dados "brutos", subjacente.
  * Entidades: Cole√ß√µes de features que s√£o semanticamente relacionadas. 
    * Name: Nome da Entidade
    * Join Keys: Identifica√ß√£o das chaves prim√°rias f√≠sicas
  * Feature Views: O Modelo de dados de uma feature store √© baseado em s√©ries temporais. Uma feature view √© um agrupamento de features, que podem ser encontrados em um mesmo data source e relacionadas √†(s) mesma(s) entidade(s).

![Feature Store Data Model](docs/img/feast-data-model.png)
  
* Offline Store: Armazenam dados hist√≥ricos das s√©ries temporais utilizados pelas features; podem ser Data Lakes, Data Warehouses etc (ex: HDFS, ADLS, Snowflake, Synapse, Redshift, etc).
* Online Store: Armazenam vetores para *serving* das features em baixa lat√™ncia. S√£o utilizados para realizar *feature lookups* online.
* Registry: Reposit√≥rio central de metadados; armazena a defini√ß√£o das features e todos os metadados relacionados. O feature registry √© utilizado na descoberta e recupera√ß√£o das features.     

O diagrama a seguir apresenta a arquitetura gen√©rica de uma feature store.

![A feature store overall architecture](docs/img/overall-architecture.png)

# Arquitetura e Funciamento do Projeto

O uso de uma feature store √© escal√°vel quando este componente integra a arquitetura / infraestrutura do ecossistema de dados preexistente. Por este motivo, o uso de um sistema *light-weight*, que √© capaz de utilizar o *compute* e o *storage* existentes, sem modifica√ß√µes no ambiente, √© vantajoso. O Feast √© um SDK que conta com poucas (em alguns casos, possivelmente nenhuma) modifica√ß√£o na infraestrutura existente. O √∫nico novo componente adicionado na feature store √© o Feature Registry; atualmente s√£o utilizados *buckets* ou *object stores* para armazenamento dos metadados das features. A arquitetura deste case, demonstra a adi√ß√£o de uma feature store √† arquitetura de dados existente de uma grande organiza√ß√£o. 

O ecossistema de dados apresentado nesta demo, conta, previamente (simulado, a infra on-prem e na cloud foi profisionada para execu√ß√£o do case), com um cluster de Big Data on-prem com os seguintes componentes: Um Cluster Hadoop com um HDFS (1 Namenode e 1 Datanode - **n√£o foi provisionado um secondary namenode, por simplicidade**) e um cluster Spark Standalone (1 master e 2 worker nodes); na cloud, este ambiente √© composto de uma Storage Account com Hierarchical Namespace habilitado (Azure Data Lake Store Gen2), Workspace Databricks e um Azure Event Hub workspace. Os componentes de infraestrutura adicionados nesta infra (considera-se que s√£o componentes n√£o existentes na infra anterior) foram, uma Storage Account (Blob Storage), utlizada como camada de armazenamento dos arquivos do Feature Registry, e um Azure Cache for Redis, utilizado como Online Store para serving de feature vectors.

O diagrama abaixo apresenta a arquitetura descrita acima, bem como o fluxo de dados e metadados neste projeto.

![Feature Store in a Hybrid Data Lake Architecture](docs/img/case-architecture.jpg)

## Ingest√£o de dados

Neste projeto foi realizado um processo de ingest√£o de dados simplificado, com a finalidade de demonstrar a ingest√£o de dados estruturados a partir de APIs abertas governamentais. Foi feita a ingest√£o de dois datasets a partir das APIs de dom√≠nio p√∫blico do [governo da cidade de chicago](https://data.cityofchicago.org/). 

### Taxi Trip API

Esta API contem dados referentes √†s viagens de taxi na cidade de Chicago, detalhes quanto ao modelo de dados desta api podem ser consultados [aqui](https://data.cityofchicago.org/Transportation/Taxi-Trips/wrvz-psew). Os dados s√£o recuperados a partir da SODA API do dataset wrvz-psew. Pra realizar a ingest√£o dos dados, foi criado um script de ingest√£o que pode ser encontrado [aqui](https://github.com/danielfaioli/my-feast/blob/master/infra/on-prem/ingest_scripts/ingest_taxy.py). O processo de ingest√£o pode ser iniciado subindo o cluster utilizando o [docker-compose](https://github.com/danielfaioli/my-feast/blob/master/infra/on-prem/docker-compose.yaml) presente no reposit√≥rio. Para facilitar o provisionamente do cluster e o start do processo de ingest√£o, foi criado o seguinte [Makefile](https://github.com/danielfaioli/my-feast/blob/master/infra/on-prem/Makefile). Para realizar uma ingest√£o rode os seguintes comandos:

‚ö†Ô∏è **WARNING** - Se voc√™ n√£o buildou as imagens do cluster spark, execute primeiro:

```shell
$ make build
```

1. Inicie o cluster 

```shell
$ make cluster
```

2. Inicie o processo de Ingest√£o 

```shell
$ make ingestion
```

‚ö†Ô∏è **WARNING** - Altere o service `workmachine` no docker-compose com o Ano/M√™s que deseja realizar a ingest√£o. 

O processo que ser√° executado realizar√° uma chamada na SODA API do dataset, realizar√° a pagina√ß√£o das requests, recuperando os registros do dataset. Em seguida, os registros s√£o convertidos em um Dataset Spark (RDD), utilizando, por default 31 parti√ß√µes (aproximadamente o n√∫mero de dias em um m√™s - isso √© feito para controlar a distribui√ß√£o de dados entre as parti√ß√µes e ao mesmo tempo evitar stages excessivamente grandes, isto √© maiores que 1000KB, no job Spark). O rdd √© ent√£o convertido em Spark DataFrame, reparticionado utilizando o campo `created`, referente ao data de cria√ß√£o do dado e √© feito √° carga no Data Lake (HDFS), na camada Bronze. O dado `n√£o √© transformado neste processo`, sendo carregado com o seguinte schema:
```text
ingestion_dataframe (pyspark.sql.DataFrame)
  - created: String
  - Body: String
```
O Campo `Body` √© uma string contendo todo o conte√∫do do registro, com a mesma formata√ß√£o da origem.

![On-premises Ingestion](docs/img/on-prem-ingestion.png)

### Weather API

Esta API contem dados referentes √†s leituras de tempo na cidade de Chicago, detalhes quanto ao modelo de dados desta api podem ser consultados [aqui](https://data.cityofchicago.org/Parks-Recreation/Beach-Weather-Stations-Automated-Sensors/k7hf-8y75). Os dados s√£o recuperados a partir da SODA API do dataset k7hf-8y75. O script que realiza a coleta dos dados da API e a publica√ß√£o das mensagens para o t√≥pico no Event Hub, pode ser encontrado [aqui](https://github.com/danielfaioli/my-feast/blob/develop/infra/cloud/fs-cloud/ingest_weather_chicago.py). √Ä fim de replicar este processo, voc√™ ir√° precisar dos seguintes recursos:

1. Azure Tenant & Subscription
2. Resource Group
3. Storage Account com Hierarchical Namespace habilitado
4. Databricks Workspace (dica: use o trial de 14 dias)
5. Service Principal (para autentica√ß√£o entre a sess√£o Spark no Databricks e a Storage Account)
6. Event Hub Workspace (Standard ou Premium - um workspace b√°sico n√£o possui suporte para captura de Eventos)

O processo executado no script de ingest√£o, consiste de uma consulta √† [API](https://data.cityofchicago.org/Parks-Recreation/Beach-Weather-Stations-Automated-Sensors/k7hf-8y75) para buscar dados di√°rios das leturas climatol√≥gicas, √© feito o controle da pagina√ß√£o da API e a cria√ß√£o de event batches para envio as√≠ncrono ao Event Hub. O Event Hub workspace est√° configurado para capturar as mensagens postadas no t√≥pico `chicago_weather_daily`; foi setado um buffer para captura das mensagens em intervalos de 3 minutos, de maneira a agregar as mensagens recebidas dentro desta janela em um √∫nico arquivo [avro](https://en.wikipedia.org/wiki/Apache_Avro). A ingest√£o destes dados para o Data Lake (na camada bronze), √© realizada pelo script que pode ser encontrado [aqui](https://github.com/danielfaioli/my-feast/blob/master/infra/cloud/fs-cloud/chicago_weather_bronze.py). Assim como na ingest√£o no on-prem, os dados brutos n√£o s√£o transformados nesse step, faz-se a inclus√£o do metadado de cria√ß√£o do dataset (`created` field). O corpo das mensgens (`Body`), s√£o armazenados na camada bronze, garantindo sua consist√™ncia com os dados da origem; √© feita a padroniza√ß√£o de formato (delta - parquet + metadados).

![Cloud ingestion](docs/img/cloud-ingestion.png)

## Feature Engineering and Register

O processo de Feature Engineering pode ser definido como a utiliza√ß√£o do conhecimento sem√¢ntico dos dados para extra√ß√£o de vari√°veis (features) a partir de dados "brutos" (o conceito de dado bruto aqui, difere da origem dos dados mas, de fato, est√° relacionado a utiliza√ß√£o de dados granulares, sem transforma√ß√µes, ou inclus√£o de regras que possam inserir vi√©s nos dados).

Os scripts de gera√ß√£o da camada `SILVER` para on on-prem e para cloud, podem ser encontrados [aqui](https://github.com/danielfaioli/my-feast/blob/master/infra/on-prem/workspace-dev/fs-hadoop/chicago_taxi_trips_silver.ipynb) e [aqui](https://github.com/danielfaioli/my-feast/blob/master/infra/cloud/fs-cloud/chicago_weather_silver.py) respectivamente. 

Dentro da perspectiva de modelagem do Data Lake, a tabela contendo as features √© um dado com selo Gold e, portanto, ser√° armazenado na camada `Gold`, tanto no Lake On-prem quanto no Lake na cloud. 

O processo de extra√ß√£o de features dos dados da camada Silver, consistem, neste case, basicamente na transforma√ß√£o e agrega√ß√£o dos dados, pr√©-processados na camada silver, para gera√ß√£o de features. Os scripts para gera√ß√£o das features `fv_chi_station_reads_hourly (cloud)` e `fv_chi_taxi_trips_hourly (on-prem)` podem ser encontrados [aqui](https://github.com/danielfaioli/my-feast/blob/master/infra/cloud/fs-cloud/chicago_weather_hourly_fs.py) e [aqui](https://github.com/danielfaioli/my-feast/blob/develop/infra/on-prem/workspace-dev/fs-hadoop/chicago_taxi_trips_hourly_gold.ipynb), respectivamente.

Ap√≥s a cria√ß√£o dos dados, f√≠sicos, das features, √© preciso realizar a defini√ß√£o e registro das features.

### fv_chi_station_reads_hourly

Para defini√ß√£o da feature `fv_chi_station_reads_hourly`, cujos dados f√≠sicos foram gerados no Data Lake na Cloug (ADLS), como apresentado na se√ß√£o anterior, deve se primeiro, configurar o `Feature Repository`; esta configura√ß√£o define os tipos de cada Store (Offline & Online) e o location do `Feature Registry`. 

A config abaixo se encontra [aqui](https://github.com/danielfaioli/my-feast/blob/master/infra/cloud/fs-cloud/station_reads_hourly_fs/feature_store.yaml)

```yml
# file path: infra/cloud/fs-cloud/station_reads_hourly_fs/feature_store.yaml
registry:
  registry_store_type: feast_azure_provider.registry_store.AzBlobRegistryStore
  path: "https://myfeastregistry.blob.core.windows.net/feast/registry.db"
project: datamaster_teste
provider: local
online_store:
    type: redis
    connection_string: "myfeastonline.redis.cache.windows.net:6379,password=<password>"
offline_store:
    type: spark # will use the active SparkSession
```