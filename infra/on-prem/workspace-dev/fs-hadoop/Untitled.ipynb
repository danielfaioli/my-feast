{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5e8e49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/lib/python3.9/dist-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-azure added as a dependency\n",
      "com.microsoft.azure#azure-data-lake-store-sdk added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-d03259a2-dab7-4341-9f53-847ae912ad74;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hadoop#hadoop-azure;3.3.1 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.5.13 in central\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.13 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound commons-codec#commons-codec;1.11 in central\n",
      "\tfound com.microsoft.azure#azure-storage;7.0.1 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.10.5 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.30 in central\n",
      "\tfound com.microsoft.azure#azure-keyvault-core;1.0.0 in central\n",
      "\tfound com.google.guava#guava;27.0-jre in central\n",
      "\tfound com.google.guava#failureaccess;1.0 in central\n",
      "\tfound com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound org.checkerframework#checker-qual;2.5.2 in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.2.0 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;1.1 in central\n",
      "\tfound org.codehaus.mojo#animal-sniffer-annotations;1.17 in central\n",
      "\tfound org.apache.hadoop.thirdparty#hadoop-shaded-guava;1.1.1 in central\n",
      "\tfound org.eclipse.jetty#jetty-util-ajax;9.4.40.v20210413 in central\n",
      "\tfound org.eclipse.jetty#jetty-util;9.4.40.v20210413 in central\n",
      "\tfound org.codehaus.jackson#jackson-mapper-asl;1.9.13 in central\n",
      "\tfound org.codehaus.jackson#jackson-core-asl;1.9.13 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      "\tfound com.microsoft.azure#azure-data-lake-store-sdk;2.3.10 in central\n",
      ":: resolution report :: resolve 834ms :: artifacts dl 50ms\n",
      "\t:: modules in use:\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.10.5 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.2.0 from central in [default]\n",
      "\tcom.google.guava#failureaccess;1.0 from central in [default]\n",
      "\tcom.google.guava#guava;27.0-jre from central in [default]\n",
      "\tcom.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;1.1 from central in [default]\n",
      "\tcom.microsoft.azure#azure-data-lake-store-sdk;2.3.10 from central in [default]\n",
      "\tcom.microsoft.azure#azure-keyvault-core;1.0.0 from central in [default]\n",
      "\tcom.microsoft.azure#azure-storage;7.0.1 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.11 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-azure;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop.thirdparty#hadoop-shaded-guava;1.1.1 from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.13 from central in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.13 from central in [default]\n",
      "\torg.checkerframework#checker-qual;2.5.2 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-core-asl;1.9.13 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-mapper-asl;1.9.13 from central in [default]\n",
      "\torg.codehaus.mojo#animal-sniffer-annotations;1.17 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-util;9.4.40.v20210413 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-util-ajax;9.4.40.v20210413 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.30 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.8.6 by [com.fasterxml.jackson.core#jackson-core;2.10.5] in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.21 by [org.slf4j#slf4j-api;1.7.30] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   26  |   0   |   0   |   2   ||   24  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-d03259a2-dab7-4341-9f53-847ae912ad74\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 24 already retrieved (0kB/15ms)\n",
      "22/05/19 20:48:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from feast import FeatureStore\n",
    "\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "\n",
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        appName(\"pyspark-notebook\").\\\n",
    "        master(\"spark://spark-master:7077\").\\\n",
    "        config(\"spark.executor.memory\", \"1g\").\\\n",
    "        config(\"spark.executor.cores\", 1).\\\n",
    "        config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-azure:3.3.1,com.microsoft.azure:azure-data-lake-store-sdk:2.3.10\").\\\n",
    "        config(\"spark.hadoop.fs.azure\", \"org.apache.hadoop.fs.azure.NativeAzureFileSystem\").\\\n",
    "        config(\"spark.hadoop.fs.azure.account.key.myfeastadls.dfs.core.windows.net\", \"U588DqWLAQQz3zoOkSTij94Me6Wfk+XrmS5Lcd0QePAiGl/LsgkFr76se9scT9w/wagZaEQmppcpTmOZi90DfA==\").\\\n",
    "        getOrCreate()\n",
    "\n",
    "os.environ[\"AZURE_TENANT_ID\"]=\"f35cc17d-4ea3-4b5f-9c1e-e6770f7c7603\"\n",
    "os.environ[\"AZURE_CLIENT_ID\"]=\"5baa3265-c1e8-44fb-bb35-c448ae261d4a\"\n",
    "os.environ[\"AZURE_CLIENT_SECRET\"]=\"Src8Q~7jJtvkbnsWEzJOu4nS5LnqZOpD4Z_5ia0a\"\n",
    "\n",
    "# spark.conf.set(\"spark.sql.sources.partitionOverwriteMode\", \"dynamic\")\n",
    "# spark.conf.set(\"fs.azure\", \"org.apache.hadoop.fs.azure.NativeAzureFileSystem\")\n",
    "# spark.conf.set(\"fs.azure.account.key.myfeastadls.dfs.core.windows.net\", os.environ[\"STORAGE_ACCOUNT_KEY\"])\n",
    "\n",
    "hdfs = \"hdfs://namenode:8020\"\n",
    "fs = FeatureStore(\"./fs_online\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4df03ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.load(f\"{hdfs}/silver/chicago/taxi_trips\")\n",
    "\n",
    "df = df.\\\n",
    "withColumn(\"event_timestamp\", F.date_format(\n",
    "    F.to_timestamp(\n",
    "        F.col(\"trip_start_timestamp\")\n",
    "    ), \"yyyy-MM-dd HH:00:00\"\n",
    ")).\\\n",
    "groupBy(\"taxi_id\", \"event_timestamp\").\\\n",
    "agg(\n",
    "    F.avg(\"trip_seconds\").alias(\"avg_trip_time\"),\n",
    "    F.avg(\"trip_miles\").alias(\"avg_trip_dist\"),\n",
    "    F.avg(\"fare\").alias(\"avg_trip_fare\"),\n",
    "    F.avg(\"tips\").alias(\"avg_trip_tips\"),\n",
    "    F.sum(\"fare\").alias(\"total_fare_hour\"),\n",
    "    F.sum(\"tips\").alias(\"total_tips_hour\"),\n",
    "    F.count(\"trip_id\").alias(\"trips_count\")\n",
    ").\\\n",
    "withColumn(\"created\", F.to_date(\"event_timestamp\", \"yyyy-MM-dd HH:00:00\"))\n",
    "# .\\\n",
    "# withColumn(\"event_timestamp\", F.unix_timestamp(F.col(\"event_timestamp\"), \"dd-MM-yyyy HH:00:00\"))\n",
    "\n",
    "\n",
    "df.repartition(\"created\").\\\n",
    "write.\\\n",
    "mode(\"overwrite\").\\\n",
    "partitionBy(\"created\").\\\n",
    "save(f\"{hdfs}/gold/chicago/f_driver_stats_hourly\")\n",
    "\n",
    "\n",
    "# withColumn(\"trip_id\", F.concat_ws(\n",
    "#     \"\",\n",
    "#     F.col(\"taxi_id\"), \n",
    "#     F.unix_timestamp(F.col(\"event_timestamp\"),\"dd-MM-yyyy HH:00:00\").cast(\"string\")\n",
    "# ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5404d58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------+-----------------+-------------+------------------+---------------+---------------+-----------+----------+\n",
      "|             taxi_id|    event_timestamp|avg_trip_time|    avg_trip_dist|avg_trip_fare|     avg_trip_tips|total_fare_hour|total_tips_hour|trips_count|   created|\n",
      "+--------------------+-------------------+-------------+-----------------+-------------+------------------+---------------+---------------+-----------+----------+\n",
      "|666aeba23a02b10b5...|2022-04-25 08:00:00|         53.0|              0.0|          3.5|               0.0|            3.5|            0.0|          1|2022-04-25|\n",
      "|6720823f69b50c9a8...|2022-04-25 08:00:00|        789.0|             2.75|        11.66|              2.01|          11.66|           2.01|          1|2022-04-25|\n",
      "|0d155321bfc93b437...|2022-04-25 11:00:00|        744.0|3.996666666666666|         13.5|0.5133333333333333|           40.5|           1.54|          3|2022-04-25|\n",
      "|a3efed94dfe3faa88...|2022-04-25 15:00:00|        360.0|             0.75|        5.875|               0.0|           23.5|            0.0|          4|2022-04-25|\n",
      "|d3e38cf4471f5b65a...|2022-04-25 00:00:00|          1.0|             0.07|         45.0|               0.0|           45.0|            0.0|          1|2022-04-25|\n",
      "+--------------------+-------------------+-------------+-----------------+-------------+------------------+---------------+---------------+-----------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6658298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feast.infra.offline_stores.contrib.spark_offline_store.spark_source import SparkSource\n",
    "from feast import Feature, FeatureView, ValueType\n",
    "from datetime import timedelta, datetime\n",
    "from feast import Entity\n",
    "\n",
    "# Feature Source Definition\n",
    "driver_stats_source = SparkSource(\n",
    "    file_format=\"parquet\",\n",
    "    path=f\"{hdfs}/gold/chicago/f_driver_stats_hourly\",\n",
    "    timestamp_field=\"event_timestamp\",\n",
    "    created_timestamp_column=\"created\",\n",
    "    name=\"f_chi_driver_stats_hourly\"\n",
    ")\n",
    "\n",
    "# Feature Definition\n",
    "driver_stats_fv = FeatureView(\n",
    "    name=\"fv_chi_driver_stats_hourly\",\n",
    "    entities=[\"driver\"],\n",
    "    features=[\n",
    "        Feature(name=\"avg_trip_time\", dtype=ValueType.FLOAT),\n",
    "        Feature(name=\"avg_trip_dist\", dtype=ValueType.FLOAT),\n",
    "        Feature(name=\"avg_trip_fare\", dtype=ValueType.FLOAT),\n",
    "        Feature(name=\"avg_trip_tips\", dtype=ValueType.FLOAT),\n",
    "        Feature(name=\"total_tips_hour\", dtype=ValueType.FLOAT),\n",
    "        Feature(name=\"trips_count\", dtype=ValueType.FLOAT),\n",
    "    ],\n",
    "    batch_source=driver_stats_source\n",
    ")\n",
    "\n",
    "# Entity definition => entity == primary key \n",
    "\n",
    "driver_entity = Entity(name=\"driver\", join_keys=[\"taxi_id\"], value_type=ValueType.STRING)\n",
    "\n",
    "fs.apply([driver_entity, driver_stats_fv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32cc7e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"spec\": {\n",
      "    \"name\": \"fv_chi_station_reads_hourly\",\n",
      "    \"features\": [\n",
      "      {\n",
      "        \"name\": \"precipitation_type\",\n",
      "        \"valueType\": \"STRING\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"avg_temp\",\n",
      "        \"valueType\": \"FLOAT\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"total_rain\",\n",
      "        \"valueType\": \"FLOAT\"\n",
      "      }\n",
      "    ],\n",
      "    \"ttl\": \"0s\",\n",
      "    \"batchSource\": {\n",
      "      \"type\": \"BATCH_SPARK\",\n",
      "      \"timestampField\": \"event_timestamp\",\n",
      "      \"createdTimestampColumn\": \"created\",\n",
      "      \"dataSourceClassType\": \"feast.infra.offline_stores.contrib.spark_offline_store.spark_source.SparkSource\",\n",
      "      \"name\": \"chi_station_reads_hourly_fv\",\n",
      "      \"sparkOptions\": {\n",
      "        \"path\": \"abfss://gold@myfeastadls.dfs.core.windows.net/chicago/weather/station_reads_hourly_fv\",\n",
      "        \"fileFormat\": \"parquet\"\n",
      "      }\n",
      "    },\n",
      "    \"online\": true\n",
      "  },\n",
      "  \"meta\": {\n",
      "    \"createdTimestamp\": \"2022-05-19T01:57:59.647444Z\",\n",
      "    \"lastUpdatedTimestamp\": \"2022-05-19T01:57:59.647444Z\"\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"spec\": {\n",
      "    \"name\": \"fv_chi_taxi_trips_hourly\",\n",
      "    \"entities\": [\n",
      "      \"trip_id\"\n",
      "    ],\n",
      "    \"features\": [\n",
      "      {\n",
      "        \"name\": \"avg_trip_time\",\n",
      "        \"valueType\": \"FLOAT\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"avg_trip_dist\",\n",
      "        \"valueType\": \"FLOAT\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"avg_trip_fare\",\n",
      "        \"valueType\": \"FLOAT\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"avg_trip_tips\",\n",
      "        \"valueType\": \"FLOAT\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"total_tips_hour\",\n",
      "        \"valueType\": \"FLOAT\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"trips_count\",\n",
      "        \"valueType\": \"FLOAT\"\n",
      "      }\n",
      "    ],\n",
      "    \"ttl\": \"0s\",\n",
      "    \"batchSource\": {\n",
      "      \"type\": \"BATCH_SPARK\",\n",
      "      \"timestampField\": \"event_timestamp\",\n",
      "      \"createdTimestampColumn\": \"created\",\n",
      "      \"dataSourceClassType\": \"feast.infra.offline_stores.contrib.spark_offline_store.spark_source.SparkSource\",\n",
      "      \"name\": \"chi_taxi_trips_hourly\",\n",
      "      \"sparkOptions\": {\n",
      "        \"path\": \"hdfs://namenode:8020/gold/chicago/f_taxi_trips_hourly\",\n",
      "        \"fileFormat\": \"parquet\"\n",
      "      }\n",
      "    },\n",
      "    \"online\": true\n",
      "  },\n",
      "  \"meta\": {\n",
      "    \"createdTimestamp\": \"2022-05-19T02:11:33.926292Z\",\n",
      "    \"lastUpdatedTimestamp\": \"2022-05-19T02:11:33.926292Z\"\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"spec\": {\n",
      "    \"name\": \"fv_chi_driver_stats_hourly\",\n",
      "    \"entities\": [\n",
      "      \"driver\"\n",
      "    ],\n",
      "    \"features\": [\n",
      "      {\n",
      "        \"name\": \"avg_trip_time\",\n",
      "        \"valueType\": \"FLOAT\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"avg_trip_dist\",\n",
      "        \"valueType\": \"FLOAT\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"avg_trip_fare\",\n",
      "        \"valueType\": \"FLOAT\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"avg_trip_tips\",\n",
      "        \"valueType\": \"FLOAT\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"total_tips_hour\",\n",
      "        \"valueType\": \"FLOAT\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"trips_count\",\n",
      "        \"valueType\": \"FLOAT\"\n",
      "      }\n",
      "    ],\n",
      "    \"ttl\": \"0s\",\n",
      "    \"batchSource\": {\n",
      "      \"type\": \"BATCH_SPARK\",\n",
      "      \"timestampField\": \"event_timestamp\",\n",
      "      \"createdTimestampColumn\": \"created\",\n",
      "      \"dataSourceClassType\": \"feast.infra.offline_stores.contrib.spark_offline_store.spark_source.SparkSource\",\n",
      "      \"name\": \"f_chi_driver_stats_hourly\",\n",
      "      \"sparkOptions\": {\n",
      "        \"path\": \"hdfs://namenode:8020/gold/chicago/f_driver_stats_hourly\",\n",
      "        \"fileFormat\": \"parquet\"\n",
      "      }\n",
      "    },\n",
      "    \"online\": true\n",
      "  },\n",
      "  \"meta\": {\n",
      "    \"createdTimestamp\": \"2022-05-19T19:43:17.269395Z\",\n",
      "    \"lastUpdatedTimestamp\": \"2022-05-19T19:43:17.269395Z\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "for f in fs.list_feature_views():\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa774dd1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"spec\": {\n",
      "    \"name\": \"fv_chi_driver_stats_hourly\",\n",
      "    \"entities\": [\n",
      "      \"driver\"\n",
      "    ],\n",
      "    \"features\": [\n",
      "      {\n",
      "        \"name\": \"avg_trip_time\",\n",
      "        \"valueType\": \"FLOAT\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"avg_trip_dist\",\n",
      "        \"valueType\": \"FLOAT\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"avg_trip_fare\",\n",
      "        \"valueType\": \"FLOAT\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"avg_trip_tips\",\n",
      "        \"valueType\": \"FLOAT\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"total_tips_hour\",\n",
      "        \"valueType\": \"FLOAT\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"trips_count\",\n",
      "        \"valueType\": \"FLOAT\"\n",
      "      }\n",
      "    ],\n",
      "    \"ttl\": \"0s\",\n",
      "    \"batchSource\": {\n",
      "      \"type\": \"BATCH_SPARK\",\n",
      "      \"timestampField\": \"event_timestamp\",\n",
      "      \"createdTimestampColumn\": \"created\",\n",
      "      \"dataSourceClassType\": \"feast.infra.offline_stores.contrib.spark_offline_store.spark_source.SparkSource\",\n",
      "      \"name\": \"f_chi_driver_stats_hourly\",\n",
      "      \"sparkOptions\": {\n",
      "        \"path\": \"hdfs://namenode:8020/gold/chicago/f_driver_stats_hourly\",\n",
      "        \"fileFormat\": \"parquet\"\n",
      "      }\n",
      "    },\n",
      "    \"online\": true\n",
      "  },\n",
      "  \"meta\": {\n",
      "    \"createdTimestamp\": \"2022-05-19T19:43:17.269395Z\",\n",
      "    \"lastUpdatedTimestamp\": \"2022-05-19T19:43:17.269395Z\"\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/feast/infra/offline_stores/contrib/spark_offline_store/spark_source.py:75: RuntimeWarning: The spark data source API is an experimental feature in alpha development. This API is unstable and it could and most probably will be changed in the future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(fs.get_feature_view(\"fv_chi_driver_stats_hourly\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3ef5f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pdf = spark.read.load(f\"{hdfs}/gold/chicago/f_driver_stats_hourly\").select(\"taxi_id\", \"event_timestamp\").filter(F.col(\"created\") <= \"2022-04-10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f9055d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pdf = pdf.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59f6e6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "taxi_id            object\n",
       "event_timestamp    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee54a303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taxi_id</th>\n",
       "      <th>event_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0c16d63294bfa9a1d6452cfaf53bd8479acb2161f88c3f...</td>\n",
       "      <td>2022-04-01 13:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dfe93dd8fbdee8c0f5f945ba532ee39b57a64c05c6ba95...</td>\n",
       "      <td>2022-04-01 13:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3c07027096c12ad3f6cc84a0914cd2d14546a3662141a1...</td>\n",
       "      <td>2022-04-01 13:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48c0b5669ed50a0dcd8bf0e69fd99bb2669cb027ec06c0...</td>\n",
       "      <td>2022-04-01 13:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21ccb8006a50da9b1bb1aa2e69d37547a7ef8bf3d2b975...</td>\n",
       "      <td>2022-04-01 13:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             taxi_id     event_timestamp\n",
       "0  0c16d63294bfa9a1d6452cfaf53bd8479acb2161f88c3f... 2022-04-01 13:00:00\n",
       "1  dfe93dd8fbdee8c0f5f945ba532ee39b57a64c05c6ba95... 2022-04-01 13:00:00\n",
       "2  3c07027096c12ad3f6cc84a0914cd2d14546a3662141a1... 2022-04-01 13:00:00\n",
       "3  48c0b5669ed50a0dcd8bf0e69fd99bb2669cb027ec06c0... 2022-04-01 13:00:00\n",
       "4  21ccb8006a50da9b1bb1aa2e69d37547a7ef8bf3d2b975... 2022-04-01 13:00:00"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pdf[\"event_timestamp\"] = pd.to_datetime(pdf[\"event_timestamp\"])\n",
    "\n",
    "pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f16826c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.event_timestamp[0].month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07320d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/feast/infra/offline_stores/contrib/spark_offline_store/spark_source.py:75: RuntimeWarning: The spark data source API is an experimental feature in alpha development. This API is unstable and it could and most probably will be changed in the future.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/feast/infra/offline_stores/contrib/spark_offline_store/spark.py:119: RuntimeWarning: The spark offline store is an experimental feature in alpha development. Some functionality may still be unstable so functionality can change in the future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "hist = fs.get_historical_features(\n",
    "    entity_df=pdf,\n",
    "    features=[\"fv_chi_driver_stats_hourly:avg_trip_time\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "238bc232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/*\n",
      " Compute a deterministic hash for the `left_table_query_string` that will be used throughout\n",
      " all the logic as the field to GROUP BY the data\n",
      "*/\n",
      "CREATE OR REPLACE TEMPORARY VIEW entity_dataframe AS (\n",
      "    SELECT *,\n",
      "        event_timestamp AS entity_timestamp\n",
      "        \n",
      "            ,CONCAT(\n",
      "                \n",
      "                    CAST(taxi_id AS STRING),\n",
      "                \n",
      "                CAST(event_timestamp AS STRING)\n",
      "            ) AS fv_chi_driver_stats_hourly__entity_row_unique_id\n",
      "        \n",
      "    FROM feast_entity_df_0bcceae99de4489398444fe8a786a842\n",
      ");\n",
      "\n",
      "---EOS---\n",
      "\n",
      "\n",
      "\n",
      "CREATE OR REPLACE TEMPORARY VIEW fv_chi_driver_stats_hourly__cleaned AS (\n",
      "\n",
      "    WITH fv_chi_driver_stats_hourly__entity_dataframe AS (\n",
      "        SELECT\n",
      "            taxi_id,\n",
      "            entity_timestamp,\n",
      "            fv_chi_driver_stats_hourly__entity_row_unique_id\n",
      "        FROM entity_dataframe\n",
      "        GROUP BY\n",
      "            taxi_id,\n",
      "            entity_timestamp,\n",
      "            fv_chi_driver_stats_hourly__entity_row_unique_id\n",
      "    ),\n",
      "\n",
      "    /*\n",
      "     This query template performs the point-in-time correctness join for a single feature set table\n",
      "     to the provided entity table.\n",
      "\n",
      "     1. We first join the current feature_view to the entity dataframe that has been passed.\n",
      "     This JOIN has the following logic:\n",
      "        - For each row of the entity dataframe, only keep the rows where the `timestamp_field`\n",
      "        is less than the one provided in the entity dataframe\n",
      "        - If there a TTL for the current feature_view, also keep the rows where the `timestamp_field`\n",
      "        is higher the the one provided minus the TTL\n",
      "        - For each row, Join on the entity key and retrieve the `entity_row_unique_id` that has been\n",
      "        computed previously\n",
      "\n",
      "     The output of this CTE will contain all the necessary information and already filtered out most\n",
      "     of the data that is not relevant.\n",
      "    */\n",
      "\n",
      "    fv_chi_driver_stats_hourly__subquery AS (\n",
      "        SELECT\n",
      "            event_timestamp as event_timestamp,\n",
      "            created as created_timestamp,\n",
      "            taxi_id AS taxi_id,\n",
      "            \n",
      "                avg_trip_time as avg_trip_time\n",
      "            \n",
      "        FROM `feast_entity_df_1016d19fdb32451fbd9ffaafa641ed23`\n",
      "        WHERE event_timestamp <= '2022-04-10T23:00:00'\n",
      "        \n",
      "    ),\n",
      "\n",
      "    fv_chi_driver_stats_hourly__base AS (\n",
      "        SELECT\n",
      "            subquery.*,\n",
      "            entity_dataframe.entity_timestamp,\n",
      "            entity_dataframe.fv_chi_driver_stats_hourly__entity_row_unique_id\n",
      "        FROM fv_chi_driver_stats_hourly__subquery AS subquery\n",
      "        INNER JOIN fv_chi_driver_stats_hourly__entity_dataframe AS entity_dataframe\n",
      "        ON TRUE\n",
      "            AND subquery.event_timestamp <= entity_dataframe.entity_timestamp\n",
      "\n",
      "            \n",
      "\n",
      "            \n",
      "            AND subquery.taxi_id = entity_dataframe.taxi_id\n",
      "            \n",
      "    ),\n",
      "\n",
      "    /*\n",
      "     2. If the `created_timestamp_column` has been set, we need to\n",
      "     deduplicate the data first. This is done by calculating the\n",
      "     `MAX(created_at_timestamp)` for each event_timestamp.\n",
      "     We then join the data on the next CTE\n",
      "    */\n",
      "    \n",
      "    fv_chi_driver_stats_hourly__dedup AS (\n",
      "        SELECT\n",
      "            fv_chi_driver_stats_hourly__entity_row_unique_id,\n",
      "            event_timestamp,\n",
      "            MAX(created_timestamp) as created_timestamp\n",
      "        FROM fv_chi_driver_stats_hourly__base\n",
      "        GROUP BY fv_chi_driver_stats_hourly__entity_row_unique_id, event_timestamp\n",
      "    ),\n",
      "    \n",
      "\n",
      "    /*\n",
      "     3. The data has been filtered during the first CTE \"*__base\"\n",
      "     Thus we only need to compute the latest timestamp of each feature.\n",
      "    */\n",
      "    fv_chi_driver_stats_hourly__latest AS (\n",
      "        SELECT\n",
      "            event_timestamp,\n",
      "            created_timestamp,\n",
      "            fv_chi_driver_stats_hourly__entity_row_unique_id\n",
      "        FROM\n",
      "        (\n",
      "            SELECT *,\n",
      "                ROW_NUMBER() OVER(\n",
      "                    PARTITION BY fv_chi_driver_stats_hourly__entity_row_unique_id\n",
      "                    ORDER BY event_timestamp DESC,created_timestamp DESC\n",
      "                ) AS row_number\n",
      "            FROM fv_chi_driver_stats_hourly__base\n",
      "            \n",
      "                INNER JOIN fv_chi_driver_stats_hourly__dedup\n",
      "                USING (fv_chi_driver_stats_hourly__entity_row_unique_id, event_timestamp, created_timestamp)\n",
      "            \n",
      "        )\n",
      "        WHERE row_number = 1\n",
      "    )\n",
      "\n",
      "    /*\n",
      "     4. Once we know the latest value of each feature for a given timestamp,\n",
      "     we can join again the data back to the original \"base\" dataset\n",
      "    */\n",
      "    SELECT base.*\n",
      "    FROM fv_chi_driver_stats_hourly__base as base\n",
      "    INNER JOIN fv_chi_driver_stats_hourly__latest\n",
      "    USING(\n",
      "        fv_chi_driver_stats_hourly__entity_row_unique_id,\n",
      "        event_timestamp\n",
      "        \n",
      "            ,created_timestamp\n",
      "        \n",
      "    )\n",
      ")\n",
      "\n",
      "---EOS---\n",
      "\n",
      "\n",
      "\n",
      "/*\n",
      " Joins the outputs of multiple time travel joins to a single table.\n",
      " The entity_dataframe dataset being our source of truth here.\n",
      " */\n",
      "\n",
      "SELECT taxi_id, event_timestamp, avg_trip_time\n",
      "FROM entity_dataframe\n",
      "\n",
      "LEFT JOIN (\n",
      "    SELECT\n",
      "        fv_chi_driver_stats_hourly__entity_row_unique_id\n",
      "        \n",
      "            ,avg_trip_time\n",
      "        \n",
      "    FROM fv_chi_driver_stats_hourly__cleaned\n",
      ") USING (fv_chi_driver_stats_hourly__entity_row_unique_id)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hist = fs.get_historical_features(\n",
    "    entity_df=pdf,\n",
    "    features=[\"fv_chi_driver_stats_hourly:avg_trip_time\"],\n",
    ")print(hist.query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8514a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/19 20:50:15 WARN TaskSetManager: Stage 3 contains a task of very large size (2987 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/05/19 20:50:20 WARN TaskSetManager: Stage 7 contains a task of very large size (2987 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------+\n",
      "|             taxi_id|    event_timestamp|avg_trip_time|\n",
      "+--------------------+-------------------+-------------+\n",
      "|1a1189d1e9f4f676b...|2022-04-07 13:00:00|        417.5|\n",
      "|1db306716ecb966d2...|2022-04-07 11:00:00|        348.0|\n",
      "|21ccb8006a50da9b1...|2022-04-01 13:00:00|       1959.0|\n",
      "|22548e10dab3e149f...|2022-04-09 13:00:00|       1060.0|\n",
      "|3730b3a4c5aa4eedb...|2022-04-09 20:00:00|       1948.0|\n",
      "|396892a80daeabb20...|2022-04-05 07:00:00|       4810.0|\n",
      "|52b413067437984fb...|2022-04-01 17:00:00|       1561.0|\n",
      "|73f6888d8d8f9808f...|2022-04-05 17:00:00|       1279.0|\n",
      "|8b16fbd9daba8152a...|2022-04-05 16:00:00|       1560.0|\n",
      "|8d9a2218e0a2c8ae9...|2022-04-09 20:00:00|        660.0|\n",
      "|8e61957eda2e69d68...|2022-04-07 22:00:00|       2460.0|\n",
      "|951920ae87e18650b...|2022-04-07 22:00:00|       1684.0|\n",
      "|a4d668e2c39ab79be...|2022-04-09 19:00:00|       1620.0|\n",
      "|a5c7281e5955cd080...|2022-04-01 19:00:00|        701.0|\n",
      "|bed942f47f98000cf...|2022-04-05 17:00:00|       2100.0|\n",
      "|ea1095a215ac661a9...|2022-04-09 07:00:00|       2332.0|\n",
      "|025c4a64d4348a818...|2022-04-01 19:00:00|        288.0|\n",
      "|1506b7c792a49f118...|2022-04-07 11:00:00|       1440.0|\n",
      "|1d09fa80d9cf790cd...|2022-04-07 17:00:00|        488.0|\n",
      "|391317d70c5d06dee...|2022-04-05 19:00:00|       1560.0|\n",
      "+--------------------+-------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hist = fs.get_historical_features(\n",
    "    entity_df=pdf,\n",
    "    features=[\"fv_chi_driver_stats_hourly:avg_trip_time\"],\n",
    ")\n",
    "\n",
    "hist.to_spark_df().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e66d4f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/feast/infra/offline_stores/contrib/spark_offline_store/spark.py:119: RuntimeWarning: The spark offline store is an experimental feature in alpha development. Some functionality may still be unstable so functionality can change in the future.\n",
      "  warnings.warn(\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "hist = fs.get_historical_features(\n",
    "    entity_df=pdf,\n",
    "    features=[\"fv_chi_station_reads_hourly:precipitation_type\"],\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2831b88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/19 21:06:35 WARN TaskSetManager: Stage 56 contains a task of very large size (2987 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/05/19 21:08:18 WARN TaskSetManager: Stage 60 contains a task of very large size (2987 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+------------------+\n",
      "|             taxi_id|    event_timestamp|precipitation_type|\n",
      "+--------------------+-------------------+------------------+\n",
      "|86b07dc8beb256766...|2022-04-05 08:00:00|              null|\n",
      "|4b92a02bf38d961c4...|2022-04-05 13:00:00|              null|\n",
      "|5129d55d3c20106ab...|2022-04-05 13:00:00|              null|\n",
      "|bed942f47f98000cf...|2022-04-05 17:00:00|              null|\n",
      "|73f6888d8d8f9808f...|2022-04-05 17:00:00|              null|\n",
      "|e01e870c967429b39...|2022-04-05 18:00:00|              null|\n",
      "|f7702c24e158419da...|2022-04-05 05:00:00|              null|\n",
      "|d634ba148906efbe2...|2022-04-05 05:00:00|              null|\n",
      "|ac1f0defd00d6b741...|2022-04-05 05:00:00|              null|\n",
      "|74b9b3ba2f90ab6df...|2022-04-05 05:00:00|              null|\n",
      "|396892a80daeabb20...|2022-04-05 07:00:00|              null|\n",
      "|391317d70c5d06dee...|2022-04-05 19:00:00|              null|\n",
      "|d6fd39863cdce9901...|2022-04-05 19:00:00|              null|\n",
      "|6720823f69b50c9a8...|2022-04-05 15:00:00|              null|\n",
      "|4d2f169ecb601e503...|2022-04-05 06:00:00|              null|\n",
      "|12c12b431a195b67d...|2022-04-05 10:00:00|              null|\n",
      "|b45a6ac97b6cb6f7a...|2022-04-05 10:00:00|              null|\n",
      "|38628169e76729f19...|2022-04-05 16:00:00|              null|\n",
      "|8b16fbd9daba8152a...|2022-04-05 16:00:00|              null|\n",
      "|666aeba23a02b10b5...|2022-04-05 16:00:00|              null|\n",
      "+--------------------+-------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hist.to_spark_df().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1d9a95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myfeast",
   "language": "python",
   "name": "myfeast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
