{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eea732d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: fs.azure.account.key.myfeastadls.dfs.core.windows.net\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/lib/python3.9/dist-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-azure added as a dependency\n",
      "com.microsoft.azure#azure-data-lake-store-sdk added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-0a9bc3b8-f14f-47bc-bd42-685917edc1c8;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hadoop#hadoop-azure;3.3.1 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.5.13 in central\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.13 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound commons-codec#commons-codec;1.11 in central\n",
      "\tfound com.microsoft.azure#azure-storage;7.0.1 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.10.5 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.30 in central\n",
      "\tfound com.microsoft.azure#azure-keyvault-core;1.0.0 in central\n",
      "\tfound com.google.guava#guava;27.0-jre in central\n",
      "\tfound com.google.guava#failureaccess;1.0 in central\n",
      "\tfound com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound org.checkerframework#checker-qual;2.5.2 in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.2.0 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;1.1 in central\n",
      "\tfound org.codehaus.mojo#animal-sniffer-annotations;1.17 in central\n",
      "\tfound org.apache.hadoop.thirdparty#hadoop-shaded-guava;1.1.1 in central\n",
      "\tfound org.eclipse.jetty#jetty-util-ajax;9.4.40.v20210413 in central\n",
      "\tfound org.eclipse.jetty#jetty-util;9.4.40.v20210413 in central\n",
      "\tfound org.codehaus.jackson#jackson-mapper-asl;1.9.13 in central\n",
      "\tfound org.codehaus.jackson#jackson-core-asl;1.9.13 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      "\tfound com.microsoft.azure#azure-data-lake-store-sdk;2.3.10 in central\n",
      ":: resolution report :: resolve 549ms :: artifacts dl 24ms\n",
      "\t:: modules in use:\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.10.5 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.2.0 from central in [default]\n",
      "\tcom.google.guava#failureaccess;1.0 from central in [default]\n",
      "\tcom.google.guava#guava;27.0-jre from central in [default]\n",
      "\tcom.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;1.1 from central in [default]\n",
      "\tcom.microsoft.azure#azure-data-lake-store-sdk;2.3.10 from central in [default]\n",
      "\tcom.microsoft.azure#azure-keyvault-core;1.0.0 from central in [default]\n",
      "\tcom.microsoft.azure#azure-storage;7.0.1 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.11 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-azure;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop.thirdparty#hadoop-shaded-guava;1.1.1 from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.13 from central in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.13 from central in [default]\n",
      "\torg.checkerframework#checker-qual;2.5.2 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-core-asl;1.9.13 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-mapper-asl;1.9.13 from central in [default]\n",
      "\torg.codehaus.mojo#animal-sniffer-annotations;1.17 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-util;9.4.40.v20210413 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-util-ajax;9.4.40.v20210413 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.30 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.8.6 by [com.fasterxml.jackson.core#jackson-core;2.10.5] in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.21 by [org.slf4j#slf4j-api;1.7.30] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   26  |   0   |   0   |   2   ||   24  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-0a9bc3b8-f14f-47bc-bd42-685917edc1c8\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 24 already retrieved (0kB/14ms)\n",
      "22/05/23 01:20:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from feast import FeatureStore\n",
    "\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "\n",
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        appName(\"pyspark-notebook\").\\\n",
    "        master(\"spark://spark-master:7077\").\\\n",
    "        config(\"spark.executor.memory\", \"1g\").\\\n",
    "        config(\"spark.executor.cores\", 1).\\\n",
    "        config(\"spark.sql.sources.partitionOverwriteMode\", \"dynamic\").\\\n",
    "        config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-azure:3.3.1,com.microsoft.azure:azure-data-lake-store-sdk:2.3.10\").\\\n",
    "        config(\"spark.hadoop.fs.azure\", \"org.apache.hadoop.fs.azure.NativeAzureFileSystem\").\\\n",
    "        config(\"fs.azure.account.key.myfeastadls.dfs.core.windows.net\", os.environ[\"STORAGE_ACCOUNT_KEY\"]).\\\n",
    "        config(\"spark.databricks.delta.formatCheck.enabled\", False).\\\n",
    "        getOrCreate()\n",
    "\n",
    "\n",
    "# spark.conf.set\n",
    "# spark.conf.set(\"fs.azure\", \"org.apache.hadoop.fs.azure.NativeAzureFileSystem\")\n",
    "# spark.conf.set(\"spark.hadoop.fs.azure.account.key.myfeastadls.dfs.core.windows.net\", \"U588DqWLAQQz3zoOkSTij94Me6Wfk+XrmS5Lcd0QePAiGl/LsgkFr76se9scT9w/wagZaEQmppcpTmOZi90DfA==\").\\\n",
    "# spark.conf.set(\"spark.databricks.delta.formatCheck.enabled\", False)\n",
    "\n",
    "# os.environ[\"AZURE_TENANT_ID\"]=\"f35cc17d-4ea3-4b5f-9c1e-e6770f7c7603\"\n",
    "# os.environ[\"AZURE_CLIENT_ID\"]=\"5baa3265-c1e8-44fb-bb35-c448ae261d4a\"\n",
    "# os.environ[\"AZURE_CLIENT_SECRET\"]=\"Src8Q~7jJtvkbnsWEzJOu4nS5LnqZOpD4Z_5ia0a\"\n",
    "\n",
    "# spark.conf.set(\"spark.sql.sources.partitionOverwriteMode\", \"dynamic\")\n",
    "# spark.conf.set(\"fs.azure\", \"org.apache.hadoop.fs.azure.NativeAzureFileSystem\")\n",
    "# spark.conf.set(\"fs.azure.account.key.myfeastadls.dfs.core.windows.net\", os.environ[\"STORAGE_ACCOUNT_KEY\"])\n",
    "\n",
    "spark.conf.set(\"fs.azure.account.key.myfeastadls.dfs.core.windows.net\", os.environ[\"STORAGE_ACCOUNT_KEY\"])\n",
    "\n",
    "hdfs = \"hdfs://namenode:8020\"\n",
    "fs = FeatureStore(\"./fs_online\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b4bdf00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities\n",
      "\n",
      "driver\n",
      "====================================================================================================\n",
      "trip_id\n",
      "====================================================================================================\n",
      "taxi_id\n",
      "====================================================================================================\n",
      "\n",
      "Feature Views\n",
      "====================================================================================================\n",
      "Feature View: fv_chi_station_reads_hourly\n",
      "\n",
      "{\n",
      "  \"spec\": {\n",
      "    \"name\": \"fv_chi_station_reads_hourly\",\n",
      "    \"features\": [\n",
      "      {\n",
      "        \"name\": \"precipitation_type\",\n",
      "        \"valueType\": \"STRING\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"avg_temp\",\n",
      "        \"valueType\": \"FLOAT\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"total_rain\",\n",
      "        \"valueType\": \"FLOAT\"\n",
      "      }\n",
      "    ],\n",
      "    \"ttl\": \"0s\",\n",
      "    \"batchSource\": {\n",
      "      \"type\": \"BATCH_SPARK\",\n",
      "      \"timestampField\": \"event_timestamp\",\n",
      "      \"createdTimestampColumn\": \"created\",\n",
      "      \"dataSourceClassType\": \"feast.infra.offline_stores.contrib.spark_offline_store.spark_source.SparkSource\",\n",
      "      \"name\": \"chi_station_reads_hourly_fv\",\n",
      "      \"sparkOptions\": {\n",
      "        \"path\": \"abfss://gold@myfeastadls.dfs.core.windows.net/chicago/weather/station_reads_hourly_fv\",\n",
      "        \"fileFormat\": \"parquet\"\n",
      "      }\n",
      "    },\n",
      "    \"online\": true\n",
      "  },\n",
      "  \"meta\": {\n",
      "    \"createdTimestamp\": \"2022-05-19T01:57:59.647444Z\",\n",
      "    \"lastUpdatedTimestamp\": \"2022-05-19T01:57:59.647444Z\"\n",
      "  }\n",
      "}\n",
      "====================================================================================================\n",
      "Feature View: fv_chi_driver_stats_hourly\n",
      "\n",
      "{\n",
      "  \"spec\": {\n",
      "    \"name\": \"fv_chi_driver_stats_hourly\",\n",
      "    \"entities\": [\n",
      "      \"driver\"\n",
      "    ],\n",
      "    \"features\": [\n",
      "      {\n",
      "        \"name\": \"avg_trip_time\",\n",
      "        \"valueType\": \"FLOAT\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"avg_trip_dist\",\n",
      "        \"valueType\": \"FLOAT\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"avg_trip_fare\",\n",
      "        \"valueType\": \"FLOAT\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"avg_trip_tips\",\n",
      "        \"valueType\": \"FLOAT\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"total_tips_hour\",\n",
      "        \"valueType\": \"FLOAT\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"trips_count\",\n",
      "        \"valueType\": \"FLOAT\"\n",
      "      }\n",
      "    ],\n",
      "    \"ttl\": \"0s\",\n",
      "    \"batchSource\": {\n",
      "      \"type\": \"BATCH_SPARK\",\n",
      "      \"timestampField\": \"event_timestamp\",\n",
      "      \"createdTimestampColumn\": \"created\",\n",
      "      \"dataSourceClassType\": \"feast.infra.offline_stores.contrib.spark_offline_store.spark_source.SparkSource\",\n",
      "      \"name\": \"f_chi_driver_stats_hourly\",\n",
      "      \"sparkOptions\": {\n",
      "        \"path\": \"hdfs://namenode:8020/gold/chicago/f_driver_stats_hourly\",\n",
      "        \"fileFormat\": \"parquet\"\n",
      "      }\n",
      "    },\n",
      "    \"online\": true\n",
      "  },\n",
      "  \"meta\": {\n",
      "    \"createdTimestamp\": \"2022-05-19T19:43:17.269395Z\",\n",
      "    \"lastUpdatedTimestamp\": \"2022-05-19T19:43:17.269395Z\"\n",
      "  }\n",
      "}\n",
      "====================================================================================================\n",
      "Feature View: fv_chi_taxi_trips_hourly\n",
      "\n",
      "{\n",
      "  \"spec\": {\n",
      "    \"name\": \"fv_chi_taxi_trips_hourly\",\n",
      "    \"entities\": [\n",
      "      \"taxi_id\"\n",
      "    ],\n",
      "    \"features\": [\n",
      "      {\n",
      "        \"name\": \"avg_trip_time\",\n",
      "        \"valueType\": \"FLOAT\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"avg_trip_dist\",\n",
      "        \"valueType\": \"FLOAT\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"avg_trip_fare\",\n",
      "        \"valueType\": \"FLOAT\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"avg_trip_tips\",\n",
      "        \"valueType\": \"FLOAT\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"total_tips_hour\",\n",
      "        \"valueType\": \"FLOAT\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"trips_count\",\n",
      "        \"valueType\": \"FLOAT\"\n",
      "      }\n",
      "    ],\n",
      "    \"ttl\": \"0s\",\n",
      "    \"batchSource\": {\n",
      "      \"type\": \"BATCH_SPARK\",\n",
      "      \"timestampField\": \"event_timestamp\",\n",
      "      \"createdTimestampColumn\": \"created\",\n",
      "      \"dataSourceClassType\": \"feast.infra.offline_stores.contrib.spark_offline_store.spark_source.SparkSource\",\n",
      "      \"name\": \"chi_taxi_trips_hourly\",\n",
      "      \"sparkOptions\": {\n",
      "        \"path\": \"hdfs://namenode:8020/gold/chicago/f_taxi_trips_hourly\",\n",
      "        \"fileFormat\": \"parquet\"\n",
      "      }\n",
      "    },\n",
      "    \"online\": true\n",
      "  },\n",
      "  \"meta\": {\n",
      "    \"createdTimestamp\": \"2022-05-23T01:15:19.458642Z\",\n",
      "    \"lastUpdatedTimestamp\": \"2022-05-23T01:15:19.458642Z\"\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/feast/infra/offline_stores/contrib/spark_offline_store/spark_source.py:75: RuntimeWarning: The spark data source API is an experimental feature in alpha development. This API is unstable and it could and most probably will be changed in the future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Feature Discovery\n",
    "\n",
    "fs = FeatureStore(\"./fs_online\")\n",
    "\n",
    "entities = fs.list_entities()\n",
    "print(\"Entities\\n\")\n",
    "for en in entities:\n",
    "    print(f\"{en.name}\")\n",
    "    print(\"=\"*100)\n",
    "\n",
    "    \n",
    "print(\"\\nFeature Views\")\n",
    "for f in fs.list_feature_views():\n",
    "    print(\"=\"*100+\"\")    \n",
    "    print(f\"Feature View: {f.name}\\n\")\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0211acb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "entity_df = spark.read.\\\n",
    "load(\"hdfs://namenode:8020/gold/chicago/f_taxi_trips_hourly\").filter(F.col(\"created\") <= \"2022-04-10\")\n",
    "# withColumn(\"read_id\", (F.unix_timestamp(F.col(\"event_timestamp\"),\"dd-MM-yyyy HH:00:00\").cast(\"string\"))).\\\n",
    "# select(\"read_id\", \"event_timestamp\").\\\n",
    "# distinct().\\\n",
    "# sort(\"read_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e583bdd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------+-------------+------------------+------------------+---------------+-----------------+-----------+----------+\n",
      "|             taxi_id|    event_timestamp|avg_trip_time|avg_trip_dist|     avg_trip_fare|     avg_trip_tips|total_fare_hour|  total_tips_hour|trips_count|   created|\n",
      "+--------------------+-------------------+-------------+-------------+------------------+------------------+---------------+-----------------+-----------+----------+\n",
      "|0c16d63294bfa9a1d...|2022-04-01 13:00:00|       1154.0|        13.55|              34.0|               7.7|           34.0|              7.7|          1|2022-04-01|\n",
      "|dfe93dd8fbdee8c0f...|2022-04-01 13:00:00|        269.8|        1.108|               7.5|             1.642|           37.5|8.209999999999999|          5|2022-04-01|\n",
      "|3c07027096c12ad3f...|2022-04-01 13:00:00|       1390.0|        12.06|31.416666666666668|6.6000000000000005|          94.25|             19.8|          3|2022-04-01|\n",
      "|48c0b5669ed50a0dc...|2022-04-01 13:00:00|        170.0|         0.25|              4.25|               0.0|           4.25|              0.0|          1|2022-04-01|\n",
      "|21ccb8006a50da9b1...|2022-04-01 13:00:00|       1959.0|        17.13|             42.25|               0.0|           84.5|              0.0|          2|2022-04-01|\n",
      "+--------------------+-------------------+-------------+-------------+------------------+------------------+---------------+-----------------+-----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "entity_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "030c3a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/feast/infra/offline_stores/contrib/spark_offline_store/spark_source.py:75: RuntimeWarning: The spark data source API is an experimental feature in alpha development. This API is unstable and it could and most probably will be changed in the future.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/feast/infra/offline_stores/contrib/spark_offline_store/spark.py:119: RuntimeWarning: The spark offline store is an experimental feature in alpha development. Some functionality may still be unstable so functionality can change in the future.\n",
      "  warnings.warn(\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "hist_features = fs.get_historical_features(\n",
    "    entity_df=entity_df.toPandas(),\n",
    "    features=[\n",
    "        \"fv_chi_station_reads_hourly:precipitation_type\",\n",
    "        \"fv_chi_station_reads_hourly:avg_temp\",\n",
    "        \"fv_chi_station_reads_hourly:total_rain\"\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6638b1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df = hist_features.to_spark_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69a52f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- taxi_id: string (nullable = true)\n",
      " |-- event_timestamp: timestamp (nullable = true)\n",
      " |-- avg_trip_time: double (nullable = true)\n",
      " |-- avg_trip_dist: double (nullable = true)\n",
      " |-- avg_trip_fare: double (nullable = true)\n",
      " |-- avg_trip_tips: double (nullable = true)\n",
      " |-- total_fare_hour: double (nullable = true)\n",
      " |-- total_tips_hour: double (nullable = true)\n",
      " |-- trips_count: long (nullable = true)\n",
      " |-- created: date (nullable = true)\n",
      " |-- precipitation_type: string (nullable = true)\n",
      " |-- avg_temp: double (nullable = true)\n",
      " |-- total_rain: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hist_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddaa7f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/23 01:33:13 WARN TaskSetManager: Stage 33 contains a task of very large size (4247 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/05/23 01:33:14 WARN TaskSetManager: Stage 34 contains a task of very large size (4247 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+------------------+------------------+------------------+----------+\n",
      "|             taxi_id|     avg_trip_time|     avg_trip_dist|precipitation_type|          avg_temp|total_rain|\n",
      "+--------------------+------------------+------------------+------------------+------------------+----------+\n",
      "|d133de68d7dfb2069...|            1932.0|              17.8|                no|               0.6|     136.2|\n",
      "|65e6fa122a48ea774...|            1797.5|             9.945|                no|0.7133333333333333|     136.2|\n",
      "|cf2a68db5901a09fc...|            3248.0|             14.29|                no|2.1233333333333335|     136.2|\n",
      "|6794d3cb4e473ce49...|1639.3333333333333| 6.713333333333334|                no|2.1233333333333335|     136.2|\n",
      "|52b413067437984fb...|            1561.0| 5.715000000000001|                no|2.1233333333333335|     136.2|\n",
      "|79014a1d9bac0ae75...|            1560.0|              11.9|                no|2.1233333333333335|     136.2|\n",
      "|5da013ec65199c182...|            2198.0|             14.42|                no|2.1233333333333335|     136.2|\n",
      "|97c6416993b8151c4...|             540.0|               0.9|                no|2.1233333333333335|     136.2|\n",
      "|0c16d63294bfa9a1d...|            1154.0|             13.55|                no|1.8333333333333333|     136.2|\n",
      "|dfe93dd8fbdee8c0f...|             269.8|             1.108|                no|1.8333333333333333|     136.2|\n",
      "|3c07027096c12ad3f...|            1390.0|             12.06|                no|1.8333333333333333|     136.2|\n",
      "|48c0b5669ed50a0dc...|             170.0|              0.25|                no|1.8333333333333333|     136.2|\n",
      "|21ccb8006a50da9b1...|            1959.0|             17.13|                no|1.8333333333333333|     136.2|\n",
      "|15b7f4c0463be79f2...|             915.0|             2.285|                no|2.0666666666666664|     136.2|\n",
      "|eeace255ebbdbaf09...|            1527.0|              5.17|                no|2.0666666666666664|     136.2|\n",
      "|f454eed0504cea35d...|            1091.0|             8.215|                no|2.0666666666666664|     136.2|\n",
      "|025c4a64d4348a818...|             288.0|0.8899999999999999|                no| 2.033333333333333|     136.2|\n",
      "|a5c7281e5955cd080...|             701.0|             5.715|                no| 2.033333333333333|     136.2|\n",
      "|57fa54b44d1e25d82...|             739.5|1.8050000000000002|                no| 2.033333333333333|     136.2|\n",
      "|c1ffe6edab518145a...|             935.0|            1.1575|                no| 2.033333333333333|     136.2|\n",
      "+--------------------+------------------+------------------+------------------+------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hist_df.select(\"taxi_id\", \"avg_trip_time\", \"avg_trip_dist\", \"precipitation_type\", \"avg_temp\", \"total_rain\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d6c923b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/23 01:43:31 WARN TaskSetManager: Stage 61 contains a task of very large size (4247 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/05/23 01:46:02 WARN TaskSetManager: Stage 65 contains a task of very large size (4247 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(taxi_id='0c16d63294bfa9a1d6452cfaf53bd8479acb2161f88c3f49cfc760ef4964b9b717e7695b79231a7dae2dc16e9aa22d4ad0feaa49138d1b15a7607e2e9c2b3286', event_timestamp=datetime.datetime(2022, 4, 1, 13, 0), avg_trip_time=1154.0, avg_trip_dist=13.55, avg_trip_fare=34.0, avg_trip_tips=7.7, total_fare_hour=34.0, total_tips_hour=7.7, trips_count=1, created=datetime.date(2022, 4, 1), precipitation_type='no', avg_temp=1.8333333333333333, total_rain=136.2)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_df.limit(1).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c62a1eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'taxi_id': ['0c16d63294bfa9a1d6452cfaf53bd8479acb2161f88c3f49cfc760ef4964b9b717e7695b79231a7dae2dc16e9aa22d4ad0feaa49138d1b15a7607e2e9c2b3286'],\n",
       " 'avg_trip_fare': [10.039999961853027],\n",
       " 'avg_trip_dist': [2.2200000286102295],\n",
       " 'avg_trip_time': [722.0]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 39666)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.9/socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.9/socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.9/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.9/socketserver.py\", line 720, in __init__\n",
      "    self.handle()\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pyspark/accumulators.py\", line 262, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pyspark/accumulators.py\", line 235, in poll\n",
      "    if func():\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pyspark/accumulators.py\", line 239, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pyspark/serializers.py\", line 564, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "entity_rows = [{\"taxi_id\": \"0c16d63294bfa9a1d6452cfaf53bd8479acb2161f88c3f49cfc760ef4964b9b717e7695b79231a7dae2dc16e9aa22d4ad0feaa49138d1b15a7607e2e9c2b3286\"}]\n",
    "\n",
    "fs.get_online_features(entity_rows=entity_rows,\n",
    "                       features=[\n",
    "                           \"fv_chi_taxi_trips_hourly:avg_trip_time\",\n",
    "                           \"fv_chi_taxi_trips_hourly:avg_trip_dist\",\n",
    "                           \"fv_chi_taxi_trips_hourly:avg_trip_fare\"\n",
    "                       ]\n",
    "                      ).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c54a77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myfeast",
   "language": "python",
   "name": "myfeast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
